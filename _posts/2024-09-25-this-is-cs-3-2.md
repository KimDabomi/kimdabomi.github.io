---
layout: single
title: "[이것이 취업을 위한 컴퓨터 과학이다] 3-4 ~ 3-6"
categories:
  - study
sidebar:
  nav: "sidebar-category"
---

## 3 - 4. CPU 스케줄링

운영체제는 다양한 프로세스와 스레드에 CPU의 사용을 배분함으로써 CPU자원을 관리함 
- CPU 스케줄링 - CPU 배분 방법
- CPU 스케줄링 알고리즘 - CPU  스케줄링의 절차
- CPU 스케줄러 - CPU 스케줄링 알고리즘을 결정하고 수행하는 운영체제의 일부분
 
운영체제는 프로세스별 우선순위를 판단하여 PCB에 명시하고, 우선순위가 높은 프로세스에는 CPU의 자원을 더 빨리, 더 많이 할당함<br />
모든 프로세스가 CPU를 차례대로 돌아가며 사용하는 것보다 상황에 맞게 CPU를 배분하는 것이 더 효율적이므로 운영체제는 프로세스마다 우선순위를 부여해 CPU를 할당함

- CPU 활용률
  - 전체 CPU의 가동 시간 중 작업을 처리하는 시간의 비율을 의미
  - 운영체제는 높은 CPU 활용률을 유지하기 위해 기본적으로 입출력 작업이 많은 프로세스의 우선순위를 높게 유지함
- CPU 버스트 - 프로세스가 CPU를 이용하는 작업
- 입출력 버스트 - 입출력장치를 기다리는 작업
- 입출력 집중 프로세스
  - 비디오 재생이나 디스크 백업 작업을 담당하는 프로세스처럼 입출력 작업이 많은 프로세스
  - 실행 상태보다 입출력을 위한 대기 상테에 더 많이 머무름
- CPU 집중 프로세스
  - 복잡한 수학 연산이나 그래픽 처리 작업을 담당하는 프로세스
  - 대기 상태보다 실행 상태에 더 많이 머무름
- 입출력 집중 프로세스와 CPU 집중 프로세스가 동시에 CPU의 자원을 요구하는 경우
  - 입출력 집중 프로세스를 가능한 빨리 실행시켜 끊임없이 입출력장치를 작동시킴
  - CPU 집중 프로세스에 집중적으로 CPU를 할당
 
**스케줄링 큐**를 통해서 운영체제가 프로세스들에게 자원을 이용하고 싶다면 서서 기다릴 줄을 구현함<br />
다음과 같은 큐들을 삽입하여 줄을 세움

- CPU를 이용하고 싶은 프로세스의 PCB
- 메모리고 적재되고 싶은 프로세스의 PCB
- 특정 입출력장치를 이용하고 싶은 프로세스의 PCB

운영체제는 큐에 삽입된 순서대로 실행하되, 우선순위가 높은 프로세스부터 먼저 실행함<br />
실행되는 프로세스가 할당받은 시간을 모두 소모할 경우 준비큐로 다시 이동하고,<br />
실행 도중 입출력 작업을 수행하는 등 대기 상태로 접어들어야 할 경우 대기 큐로 이동하게 됨

- 준비 큐 - CPU를 이용하고 싶은 프로세스의 PCB가 서는 줄
- 대기 큐 - 대기 상태에 접어든 프로세스의 PCB가 서는 줄
> 완료 인터럽트 발생 → 대기 큐에서 작업이 완료된 PCB를 찾음 → PCB를 준비 상태로 변경 →  큐에서 제거 →  PCB는 준비 큐로 이동
 
**선점형 스케줄링**은 어떤 프로세스가 CPU를 할당받아 사용하고 있더라도 운영체제가 프로세스로부터 CPU 자원을 강제로 빼앗아 다른 프로세스에 할당할 수 있는 스케줄링<br />
**비선점형 스케줄링**은 어떤 프로세스가 CPU를 사용하고 있을 때 그 프로세스가 종료되거나 스스로 대기 상태에 접어들기 전까지는 다른 프로세스가 끼어들 수 없는 스케줄링

- 선점형 스케줄링이 수행되는 시점
  - 실행 상태 → 대기 상태(입출력 작업)
    - 이 경우에서만 비선점형 스케줄링 수행됨
  - 실행 상태 → 준비 상태(타이머 인터럽트) 
- 선점형 스케줄링
  - 언제든 더 급한 프로세스가 끼어들어 CPU를 사용할 수 있으므로 한 프로세스의 CPU 독점을 막고, 여러 프로세스에 골고루 CPU 자원을 배분할 수 있음
  - 문맥 교환 과정에서 오버헤드가 발생할 수 있음
- 비선점형 스케줄링
  - 선점형 스케줄링보다 문맥 교환의 횟수가 적기 때문에 상대적으로 오버헤드의 발생이 적음
  - 어떤 프로세스가 CPU를 사용 중이라면 당장 CPU를 사용해야 하는 프로세스라도 기다려야 함
 
**CPU 스케줄링 알고리즘**이란 운영체제가 프로세스에 CPU를 배분하는 방법

- 선입 선처리 스케줄링
  - 단순히 준비 큐에 삽입된 순서대로 먼저 CPU를 요청한 프로세스부터 CPU를 할당하는 방식
  - 프로세스들이 기다리는 시간이 매우 길어질 수 있음
  - 호위 효과 - 먼저 삽입된 프로세스의 오랜 실행 시간으로 인해 나중에 삽입된 프로세스의 실행이 지연되는 문제
- 최단 작업 우선 스케줄링
  - 준비 큐에 삽입된 프로세스 중 CPU를 이용하는 시간의 길이가 가장 짧은 프로세스부터 먼저 실행하는 방식
- 라운드 로빈 스케줄링
  - 선입 선처리 스케줄링에 타임 슬라이스라는 개념이 더해진 방식
  - 타임 슬라이스 - 프로세스가 CPU를 사용하도록 정해진 시간
  - 프로세스가 정해진 시간을 모두 사용하고도 완료되지 않으면 문맥 교환이 발생해 다시 큐의 맨 뒤에 삽입됨
- 최소 잔여 시간 우선 스케줄링
  - 최단 작업 우선 스케줄링과 라운드 로빈 스케줄링을 합친 방식
  - 정해진 타임 슬라이스만큼 CPU를 이용 + 남아 있는 작업시간이 가장 적은 프로세스를 다음 프로세스로 선택
- 우선순위 스케줄링
  - 프로세스에 우선순위를 부여하고, 가장 높은 우선순위를 가진 프로세스부터 실행하는 방식
  - 아사 현상 - 우선순위가 낮은 프로세스는 준비 큐에 먼저 삽입되었더라도 우선순위가 높은 프로세스로 인해 계속해서 실행이 연기될 수 있는 현상
  - 에이징 - 오랫동안 대기한 프로세스의 우선순위를 점차 높이는 방식
- 다단계 큐 스케줄링
  - 우선순위 스케줄링의 발전된 형태, 우선순위별로 여러 개의 준비 큐를 사용하는 방식
  - 프로세스들이 큐 사이를 이동할 수 없기 때문에 우선순위가 낮은 프로세스의 작업이 계속해서 연기될 수 있음
- 다단계 피드백 큐 스케줄링
  - 다단계 큐 스케줄링과 비슷하게 동작하지만, 프로세스들이 큐 사이를 이동할 수 있음
  - 비교적 CPU를 오래 사용해야 하는 CPU 집중 프로세스들의 우선순위는 낮아지고, 비교적 CPU를 적게 사용해야 하는 입출력 집중 프로세스들은 우선순위가 높은 큐에서 실행이 끝남
  
**리눅스 CPU 스케줄링 정책**은 새로운 프로세스를 언제 어떻게 선택하여 실행할지를 결정하기 위한 규칙의 집합

- SCHED_FIFO, SCHED_RR 
  - RT 스케줄러에 의해 이뤄지는 스케줄링
  - 실시간성이 강조된 프로세스에 적용되는 스케줄링 정책
- SCHED_NORMAL 
  - 일반적인 프로세스에 적용되는 스케줄링 정책
  - CFS라는 CPU 스케줄러에 의해 스케줄링이 이뤄짐
  - CFS - 프로세스에 대해 완전히 공평한 CPU 시간 배분을 지향하는 CPU 스케줄러
    - 가상 실행 시간(프로세스의 가중치를 고려한 시간)이 가장 작은 프로세스부터 스케줄링
    - 프로세스의 우선순위가 높아질수록 가중치도 높아짐
    - 프로세스의 가중치가 높을수록 먼저 스케줄링될 확률이 높고, 타임 슬라이스도 크게 할당받을 수 있음 

## 3 - 5. 가상 메모리

- 물리 주소 - 메모리의 하드웨어 상 실제 주소
- 논리 주소 - 프로세스마다 부여되는 0번지부터 시작하는 주소 체계
- CPU와 프로세스는 논리 주소 체계를 이용함
- 메모리 관리 장치(MMU) - CPU와 메모리 사이에 위치하며, CPU가 이해하는 논리 주소를 메모리가 이해하는 물리 주소로 변환해줌

**스와핑**이란 입출력 작업을 요구하며 대기 상태가 되었거나 오랫동안 사용되지 않은 프로세스들을 임시로 **스왑 영역**이라는 보조기억장치의 일부인 영역으로 쫓아내고, 프로세스를 쫓아낸 자리에 생긴 메모리 상의 빈 공간에 다른 프로세스를 적재하여 실행하는 관리 방식
- 스왑 아웃 - 현재 실행되지 않는 프로세스가 메모리에서 스왑 영역으로 옮겨지는 것
- 스왑 인 - 스왑 영역에 있는 프로세스가 다시 메모리로 옮겨오는 것
 
**연속 메모리 할당**이란 프로세스에 연속적인 메모리 공간을 할당하는 방식
- 외부 단편화라는 문제를 내포하기 때문에, 메모리를 효율적으로 사용하는 방법은 아님
- 외부 단편화 - 프로세스 바깥에 생기는 빈 공간들은 분명 빈 공간이 맞지만 그보다 큰 프로세스를 적재하기 어려운 상황을 초래하고, 이렇게 메모리 낭비로 이어지는 현상
 

**가상 메모리**
- 실행하고자 하는 프로그램의 일부만 메모리에 적재해, 실제 메모리보다 더 큰 프로세스를 실행할 수 있도록 만드는 메모리 관리 기법
- 보조기억장치의 일부를 메모리처럼 사용하거나 프로세스의 일부만 메모리에 적재함으로써 메모리를 실제 크기보다 더 크게 보이게 하는 기술
 
**페이징**
- 프로세스의 논리 주소 공간을 페이지라는 일정한 단위로 나누고, 물리 주소 공간을 페이지와 동일한 크기의 프레임이라는 일정한 단위로 나눈 뒤, 페이지를 프레임에 할당하는 가상 메모리 관리 기법
- 프로세스를 구성하는 페이지는 물리 메모리 내에 불연속적으로 배치될 수 있음
- 페이지 아웃 - 페이징 시스템에서의 페이지 단위로 스왑 아웃 되는 것
- 페이지 인 - 페이징 시스템에서의 페이지 단위로 스왑 인 되는 것
 
**페이지 테이블**
- 프로세스의 페이지와 실제로 적재된 프레임을 짝지어주는 정보
- 프로세스마다 각자의 페이지 테이블 정보를 갖고 있으므로, CPU가 서로 다른 프로세스를 실행할 때는 각 프로세스의 페이지 - 테이블을 참조하여 메모리에 접근함
- 테이블 앤트리 - 페이지 테이블을 구성하고 있는 각각의 행
  - 페이지 번호, 프레임 번호, 유효 비트, 보호 비트, 참조 비트, 수정 비트 등이 대표적으로 포함됨
  - 유효 비트
  - 해당 페이지에 접근이 가능한지 여부를 알려 주는 중요한 정보
  - 현재 페이지가 메모리, 아니면 보조기억장치에 적재되어 있는지 알려주는 비트
  - CPU가 유효 비트가 0인 페이지에 접근하려고 하면 페이지 폴트라는 예외 발생
    - 페이지 폴트 처리 과정
    - 기존 작업 내역 백업 → 페이지를 메모리로 가져와 유효 비트 1로 변경 → 메모리에 적재된 페이지 실행
  - 보호 비트
    - 페이지 보호 기능을 위해 존재하는 비트
    - 페이지에 접근할 권한을 제한함으로써 페이지를 보호함
  - 참조 비트
    - CPU가 해당 페이지에 접근한 적이 있는지의 여부를 나타내는 비트
  - 수정 비트(더티 비트)
    - 해당 페이지에 데이터를 쓴 적이 있는지의 여부를 알려주는 비트
    - 수정 비트가 1일 경우, 보조기억장치에 대한 쓰기 작업이 필요함
    - 수정 비트가 0일 경우, 보조기억장치에 대한 쓰기 작업 없이 페이지를 메모리에서 삭제하기만 해도 됨
- 내부 단편화 - 페이지 하나의 크기보다 작은 크기로 발생하게 되는 메모리 낭비
- 페이지 테이블 베이스 레지스터(PTBR)
  - 특정 프로세스의 페이지 테이블이 적재된 메모리 상의 위치를 가리키는 레지스터
  - 프로세스마다 가지는 정보이므로 각 PCB에 기록되며, 다른 프로세스로의 문맥 교환이 발생할 때 변경됨
- 운영체제는 모든 페이지 테이블을 메모리에 적재하는 것을 가급적 지양함
  - TLB
    - 메모리 접근 횟수가 많아지는 문제를 해결하기 위해 사용되는 페이지 테이블의 캐시메모리
    - 페이지 테이블의 캐시이므로 참조 지역성의 원리에 근거해 자주 사용할 법한 페이지 위주로 페이지 테이블의 일부 내용을 저장함
    - TLB 히트 - CPU에게 해당 페이지 번호가 적재된 프레임 번호를 알려주는 것
    - TLB 미스 - 페이지 번호가 TLB에 없는 경우에 페이지가 적재된 프레임을 알기 위해 메모리 내의 페이지 테이블에 접근하는 것
    - 메모리 접근 횟수를 낮추려면 TLB 히트율을 높여야 함
  - 계층적 페이징(다단계 페이지 테이블) 
    - 페이지 테이블을 페이징하는 방식. 여러 단계의 페이지를 둠
    - CPU와 가장 가까이 위치한 페이지 테이블만 메모리에 유지하면 잘린 페이지 테이블의 일부가 보조기억장치에 있더라도 앞의 테이블을 통해서 언제든 접근 가능함
 
**페이징 주소 체계 - <페이지 번호, 변위>**
- 페이지 번호 - 몇 번째 페이지 번호에 접근할지를 나타냄
- 변위 - 접근하려는 주소가 페이지(프레임) 시작 번지로부터 얼마만큼 떨어져 있는지를 나타냄
- 요구 페이징
  - 메모리에 프로세스를 적재할 때 처음부터 모든 페이지를 적재하지 않고, 메모리에 필요한 페이지만을 적재하는 기법
  - CPU가 특정 페이지에 접근하는 명령어 실행 → 해당 페이지가 유효 비트가 1일 경우 CPU는 페이지가 적재된 프레임에 접근 → 유효비트가 0일 경우 페이지 폴트 발생 → 페이지 폴트가 발생하면 해당 페이지를 메모리로 적재하고, 유효 비트를 1로 설정 → 다시 실행
- 순수 요구 페이징 - 아무런 페이지도 메모리에 적재하지 않은 채 무작정 프로세스를 실행함
- 페이지 교체 알고리즘 - 메모리에 페이지가 가득 찬 상황에서 추가적으로 페이지를 적재해야 한다면, 메모리에 적재된 일부 페이지를 스왑 아웃 해야 함. 이때 메모리에 적재된 페이지 중 보조기억장치로 내보낼 페이지를 선택하는 방법
  - FIFO 페이지 교체 알고리즘 - 이름 그대로 메모리에 가장 먼저 적재된 페이지부터 스왑 아웃하는 페이지 교체 알고리즘
  - 최적 페이지 교체 알고리즘 - 앞으로의 사용 빈도가 가장 낮은 페이지를 교체하는 알고리즘 (실제 구현 어려움)
  - LRU 페이지 교체 알고리즘 - 가장 적게 사용한 페이지를 교체하는 알고리즘. 보편적으로 사용되는 페이지 교체 알고리즘의 원형
  
## 3 - 6. 파일 시스템

파일 시스템이란 보조기억장치의 정보를 파일 및 디렉터리의 형태로 저장하고 관리할 수 있도록하는 운영체제 내부 프로그램
- 파일
  - 파일의 이름, 파일을 실행하기 위한 정보, 파일과 관련한 부가 정보(속성, 메타데이터)로 구성됨
  - 파일 속성 - 파일의 형식, 위치, 크기 등 파일과 관련한 다양한 정보가 포함되어 있음
  - 응용 프로그램은 임의로 파일을 할당받아 조작하고 저장할 수 없고, 파일을 다루는 시스템 콜을 이용해야 함
  - 프로세스는 할당을 받아 사용 중인 파일을 구분할 수 있어야 함. 이를 위해 프로세스는 파일 디스크립터라는 정보를 사용함
  - 운영체제는 프로세스가 새로 파일을 열거나 생성할 때 해당 파일에 대한 파일 디스크립터를 프로세스에 할당함
- 디렉터리
  - 운영체제는 여러 파일들을 일목요연하게 관리하기 위해 디렉터리를 이용함
  - 디렉터리는 여러 계층을 가진 트리 구조 리렉터리로 관리됨
  - 경로 - 디렉터리 정보를 활용해 파일 위치를 특정하는 정보
  - 디렉터리 엔트리 - 디렉터리에 속한 요소의 관련 정보는 테이블의 형태로 표현되며, 테이블 형태로 표현된 정보의 행으로 파일의 이름, 파일이 저장된 위치를 유추할 수 있는 정보( 파일의 아이노드 번호 )가 반드시 포함됨 
- 파일 할당
  - 블록 - 운영체제가 파일과 디렉터리를 읽고 쓰는 단위
    - 하나의 파일이 보조기억장치에 저장될 때에는 하나 이상의 블록을 할당받아 저장됨
  - 연결 할당 - 각 블록의 일부에 다음 블록의 주소를 저장하여 각각의 블록이 다음 블록을 가리키는 형태. 디렉터리 엔트리에는 첫 - 번째 블록 주소와 파일을 이루는 블록 단위의 길이가 명시됨
  - 색인 할당 - 파일을 이루는 모든 블록의 주소를 색인 블록에 모아서 관리하는 방식. 디렉터리 엔트리에는 파일 이름과 함께 색인 블록 주소가 명시됨
  - 포매팅 - 파일 시스템을 설정하여 어떤 방식으로 파일을 저장하고 관리할 것인지를 결정하고, 새로운 데이터를 쓸 준비를 하는 작업
  - 아이노드 - 색인 블록. 파일이 저장된 위치와 속성 등 사실상 (파일의 이름을 제외한) 파일의 모든 것이 담겨 있음
- 아이노트 기반 파일 시스템
  - 파일마다 각각의 아이노드를 가지고 있으며, 아이노드에는 각가의 번호가 부여되어 있음
  - 블록 그룹
    - 슈퍼 블록 - 아이노드의 개수, 총 블록 개수, 블록 크기 등 전체적인 파일 시스템의 정보를 저장
    - 그룹 식별자 - 블록 그룹에 대한 메타데이터를 저장
    - 블록 비트맵 - 현재 블록 그룹 내에서 데이터가 어떻게 할당되었는지를 저장
    - 아이노드 비트맵 - 현재 블록 그룹 내에서 아이노드가 어떻게 할당되었는지를 저장
    - 아이노트 테이블 - 각 파일의 아이노드 정보를 저장
    - 데이터 블록 - 각 파일의 데이터를 저장
  - 아이노드 기반 파일 시스템에서는 데이터 영역에 공간이 남아 있더라도 아이노드 영역이 가득 차 더 이상의 아이노드를 할당할 수 없다면 운영체제는 새로운 파일을 생성할 수 없음
    - 하드 링크
      - 원본 파일과 같은 아이노드를 공유하는 파일
      - 하드 링크 파일을 변경하면 원본 파일도 변경됨
      - 하드 링크 파일이 남아있다면 원본 파일이 삭제되거나 이동되더라도 파일 데이터에 접근할 수 있음
    - 심볼릭 링크
      - 원본 파일을 가리키는 파일
      - 원본파일이 삭제되거나 이동되는 경우에는 사용이 불가능
      - 복잡한 경로에 있는 파일을 바로가기 파일의 형태로 간단하게 참고하고 싶을 때 유용
  - 마운트 - 어떤 저장장치의 파일 시스템에서 다른 저장장치의 파일 시스템으로 접근할 수 있도록 파일 시스템을 편입시키는 작업
  
### 요약
- **CPU 스케줄링**: 프로세스에 CPU 자원을 어떻게 배분할지 결정하는 과정.
- **우선순위**: 운영체제는 각 프로세스에 우선순위를 부여하고, 높은 우선순위의 프로세스에 더 많은 CPU 자원을 할당.
- **큐**: 프로세스들은 준비 큐와 대기 큐에서 관리되며, 우선순위에 따라 실행됨.
- **선점형 vs 비선점형**: 선점형은 다른 프로세스가 끼어들 수 있는 반면, 비선점형은 현재 프로세스가 종료될 때까지 기다려야 함.
- **스케줄링 알고리즘**: 선입 선처리, 최단 작업 우선, 라운드 로빈, 우선순위 스케줄링 등 다양한 방식이 있음.

<br />

- **가상 메모리**: 실제 메모리보다 더 큰 프로세스를 실행하기 위해 일부 페이지만 메모리에 적재하는 기법.
- **페이징**: 논리 주소 공간을 페이지로 나누고, 물리 주소 공간을 프레임으로 나누어 매핑.
- **페이지 테이블**: 각 프로세스의 페이지와 프레임 정보를 저장.
- **페이지 폴트**: 유효 비트가 0인 페이지에 접근할 때 발생하며, 해당 페이지를 메모리에 적재.
- **요구 페이징**: 필요한 페이지만 메모리에 적재하는 방식.
 
<br />

- **파일 시스템**: 보조기억장치의 정보를 파일과 디렉터리 형태로 관리.
- **파일 속성**: 파일의 형식, 크기, 위치 등 다양한 정보 포함.
- **디렉터리**: 파일을 계층적으로 관리하며, 경로를 통해 파일 위치를 지정.
- **아이노드**: 파일의 메타데이터를 저장하는 구조체.
- **링크**: 하드 링크와 심볼릭 링크로 파일을 참조하는 방식이 다름.
 
### 처음 알게 된 사실 & 어려웠던 부분
페이지 테이블, 페이지 폴트는 익숙하지 않아서 꽤나 집중해서 읽었다.<br />
논리 주소 생성 - 페이지 테이블 참조 - 프레임 확인 - 유효 비트 확인 - 0인 경우 페이지 폴트 발생, 페이지를 메모리에 옮기고 페이지 테이블을 업데이트  

### Quiz
> 다음 중 CPU 스케줄링의 주된 목적은 무엇인가요?

1) 프로세스의 메모리 사용량을 최소화한다.<br />
2) CPU 자원을 효율적으로 배분한다.<br />
3) 프로세스의 실행 속도를 최대화한다.<br />
4) 입출력 작업의 빈도를 높인다.<br />

> 가상 메모리에서 페이지 폴트가 발생하는 경우는 어떤 상황인가요?

1) 프로세스가 종료되었을 때<br />
2) 유효 비트가 1인 페이지에 접근할 때<br />
3) 유효 비트가 0인 페이지에 접근할 때<br />
4) 페이지가 메모리에 이미 적재되어 있을 때<br />

> 하드 링크와 심볼릭 링크의 차이로 옳은 것은 무엇인가요?

1) 하드 링크는 원본 파일과 다른 아이노드를 가진다.<br />
2) 심볼릭 링크는 원본 파일의 위치를 직접 참조한다.<br />
3) 하드 링크는 원본 파일이 삭제되면 사용할 수 없다.<br />
4) 심볼릭 링크는 동일한 아이노드를 공유한다.

<details>
<summary>정답</summary>
1. (2)  /  2. (3)  /  3. (2)
</details>
